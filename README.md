# COSNet
Code for CVPR 2019 paper: See More, Know More: Unsupervised Video Object Segmentation with
Co-Attention Siamese Networks.[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Lu_See_More_Know_More_Unsupervised_Video_Object_Segmentation_With_Co-Attention_CVPR_2019_paper.pdf)
The pre-trained model and testing code:
##

![](../master/framework.png)

### Quick Start

1. Install pytorch (version:1.0.1)

2. Download the pretrained model. Run 'test_iteration_conf.py' and change the davis dataset path, pretrainde model path and result path.

The pretrained weight can be download from [GoogleDrive](https://drive.google.com/open?id=14ya3ZkneeHsegCgDrvkuFtGoAfVRgErz)

### Citation
If you find the code and dataset useful in your research, please consider citing:
@InProceedings{Lu_2019_CVPR,
author = {Lu, Xiankai and Wang, Wenguan and Ma, Chao and Shen, Jianbing and Shao, Ling and Porikli, Fatih},
title = {See More, Know More: Unsupervised Video Object Segmentation With Co-Attention Siamese Networks},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}
